{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,glob,os,secrets\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import operator\n",
    "import functools\n",
    "from operator import methodcaller\n",
    "\n",
    "URL = 'https://www.uniprot.org/uploadlists/'\n",
    "\n",
    "def create_chunks(list_name, n):\n",
    "    for i in range(0, len(list_name), n):\n",
    "        yield list_name[i:i + n]\n",
    "        \n",
    "def mapping_ids(ids2map, source_fmt='P_GI',target_fmt='ACC', output_fmt='tab'):\n",
    "    if hasattr(ids2map, 'pop'):\n",
    "            ids2map = ' '.join(ids2map)\n",
    "    params = {\n",
    "    'from': source_fmt,\n",
    "    'to': target_fmt,\n",
    "    'format': output_fmt,\n",
    "    'query': ids2map\n",
    "    }\n",
    "\n",
    "    data = urllib.parse.urlencode(params)\n",
    "    data = data.encode('utf-8')\n",
    "    req = urllib.request.Request(URL, data)\n",
    "    with urllib.request.urlopen(req) as f:\n",
    "        response = f.read().decode('utf-8')\n",
    "    return response\n",
    "\n",
    "def concat_dfs(path,extension):\n",
    "    extension = extension\n",
    "    all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "    \n",
    "    combined_dfs = pd.concat([pd.read_table(f) for f in all_filenames ])\n",
    "    \n",
    "    return combined_dfs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_besthits = pd.read_table(\"C:/Users/eulle/Documents/besthits/besthits_ROCHA2.csv\")\n",
    "\n",
    "columns_csv = ['qseqid' ,'sseqid' ,'pident' ,'length','mismatch','gapopen','qstart' ,'qend' ,'sstart' ,'send' ,'evalue' ,'bitscore']\n",
    "row_values = pd.Series(df_besthits.columns)\n",
    "df_besthits = pd.DataFrame(np.vstack([df_besthits.columns,df_besthits]))\n",
    "df_besthits.columns = columns_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi_number = [re.findall(r\"(?<=GI:|gi:).*?(?=\\||p)\", ii[1]['sseqid']) for ii in df_besthits.iterrows()]\n",
    "gi_number = functools.reduce(operator.iconcat, gi_number, [])\n",
    "gi_number = list(set(gi_number))\n",
    "\n",
    "uniprot_id = [re.findall(r\"(?<=BL:|ot:).*?(?=\\||p)\",ii[1]['sseqid']) for ii in df_besthits.iterrows()]\n",
    "uniprot_id = functools.reduce(operator.iconcat, uniprot_id, [])\n",
    "uniprot_id = list(set(uniprot_id))\n",
    "\n",
    "chunk_gi = list(create_chunks(gi_number,1000))\n",
    "chunk_uniprot = list(create_chunks(uniprot_id,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma função para escrever os arquivos\n",
    "map_gi = ThreadPool(10).imap(mapping_ids,chunk_gi)\n",
    "map_uniprot = ThreadPool(10).imap(functools.partial(mapping_ids,source_fmt='ACC',target_fmt='KO_ID'),chunk_uniprot)\n",
    "\n",
    "for index,ii in enumerate(map_gi): \n",
    "    with open('C:/Users/eulle/Documents/gi_number-uni/'+ str(index)+'.csv', 'w') as file:\n",
    "        file.write(ii)\n",
    "        \n",
    "for index,ii in enumerate(map_uniprot): \n",
    "    with open('C:/Users/eulle/Documents/uniprot-ko_id/'+ str(index)+'.csv', 'w') as file:\n",
    "        file.write(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pensar em uma forma de melhorar esses downloads\n",
    "gi_uniprot_concat = concat_dfs(os.chdir(\"C:/Users/eulle/Documents/gi_number-uni/\"),\"csv\")\n",
    "gi_uniprot_concat = gi_uniprot_concat.drop_duplicates(\"From\")\n",
    "gi_uniprot_concat = gi_uniprot_concat.reset_index(drop=True)\n",
    "gi_uniprot_concat.columns = [\"GI\",\"Uniprot_ID\"]\n",
    "\n",
    "gi_uniprot_concat.to_csv(\"df_gi_uniprot.csv\",sep=\"\\t\",encoding=\"utf-8\",index=False)\n",
    "\n",
    "list_gi_uniprot = list(gi_uniprot_concat[\"Uniprot_ID\"])\n",
    "chunk_uniprot = list(create_chunks(list_gi_uniprot,1000))\n",
    "map_uniprot = ThreadPool(10).imap(functools.partial(mapping_ids,source_fmt='ACC',target_fmt='KO_ID'),chunk_uniprot)\n",
    "\n",
    "for index,ii in enumerate(map_uniprot): \n",
    "    with open('C:/Users/eulle/Documents/uniprot-ko_id/'+ secrets.token_hex(15) +'.csv', 'w') as file:\n",
    "        file.write(ii)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_ko_concat = concat_dfs(os.chdir(\"C:/Users/eulle/Documents/uniprot-ko_id/\"),\"csv\")\n",
    "uniprot_ko_concat.columns = [\"Uniprot_ID\",\"KO\"]\n",
    "uniprot_ko_concat = uniprot_ko_concat.reset_index(drop=True)\n",
    "\n",
    "uniprot_ko_concat.to_csv(\"df_ko_ids_CoSQG.csv\",sep=\"\\t\",encoding=\"utf-8\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
